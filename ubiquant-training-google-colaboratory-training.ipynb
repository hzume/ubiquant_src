{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2254,"status":"ok","timestamp":1644236470537,"user":{"displayName":"巨峰","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ312ml7sKAt5HJP_fBP-ooQm_1_LlrntDA9sW0g=s64","userId":"02610628405275685183"},"user_tz":-540},"id":"oDJWpyf2wRin","outputId":"d9f73bd4-6067-4e05-c853-100602e561e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/MyDrive/Kaggle/UbiquantMarketPredictionDrive/zume/ubiquant_src\"\n","!git pull"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":470,"status":"ok","timestamp":1644236471668,"user":{"displayName":"巨峰","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ312ml7sKAt5HJP_fBP-ooQm_1_LlrntDA9sW0g=s64","userId":"02610628405275685183"},"user_tz":-540},"id":"iO6Pl5tAvcxN","outputId":"a0d6ca9e-6a3b-40b2-84cc-6839220e1a32"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: nvidia-smi: command not found\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2MrvRuLrvcxP"},"outputs":[],"source":["class Config:\n","    author = \"zume\" # Your name\n","    competition = \"ubiquant-market-prediction\"\n","    name = \"UMP-Exp003-ColabTraining\" # The name of the Dataset\n","    upload_from_colab = True # If True, the model uploads to the Kaggle Dataset\n","    \n","    colab_dir = \"/content/drive/MyDrive/Kaggle/UbiquantMarketPredictionDrive\" # Your own directory\n","    drive_path = colab_dir + f\"/{author}\"\n","    api_path = \"/content/drive/MyDrive/Kaggle/kaggle.json\" # Your own api-path\n","    \n","    dataset_path = ['robikscube/ubiquant-parquet'] # The dataset you want to download\n","\n","    n_fold = 5\n","    n_test = 2\n","    purge = 10\n","    embargo = 0.01\n","    \n","    from scipy.special import comb\n","    trn_fold = [i for i in range(comb(n_fold, n_test, exact=True))]\n","    seed = 42\n","    max_epochs = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M4BWPj1qvcxR"},"outputs":[],"source":["import os\n","import gc\n","import sys\n","import json\n","import pickle\n","import shutil\n","import random\n","import joblib\n","import requests\n","import itertools\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from glob import glob\n","from tqdm.auto import tqdm\n","\n","from logging import StreamHandler, FileHandler, Formatter, getLogger, DEBUG, INFO\n","\n","from sklearn.preprocessing import (\n","    StandardScaler,\n","    MinMaxScaler,\n","    RobustScaler,\n",")\n","from sklearn.linear_model import (\n","    Ridge,\n",")\n","from sklearn.metrics import (\n","    accuracy_score,\n","    f1_score,\n","    log_loss,\n","    roc_auc_score,\n","    mean_absolute_error,\n","    mean_squared_error,\n",")\n","\n","import lightgbm as lgbm\n","import torch\n","import tensorflow as tf\n","import scipy\n","\n","sys.path.append(\"/content/drive/MyDrive/Kaggle/UbiquantMarketPredictionDrive/zume/ubiquant_src\")\n","import mycv\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","def MAE(y_true, y_pred):\n","    return mean_absolute_error(y_true, y_pred)\n","\n","def MSE(y_true, y_pred):\n","    return mean_squared_error(y_true, y_pred)\n","\n","def RMSE(y_true, y_pred):\n","    return mean_squared_error(y_true, y_pred, squared=False)\n","\n","def PearsonR(y_true, y_pred):\n","    return scipy.stats.pearsonr(y_true, y_pred)[0]\n","\n","def PearsonR_metric(y_true, y_pred):\n","    return \"pearsonr\", scipy.stats.pearsonr(y_true, y_pred)[0], True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKeJYuRvvcxU"},"outputs":[],"source":["def setup(cfg):\n","    cfg.COLAB = 'google.colab' in sys.modules\n","    if cfg.COLAB:\n","        global logger\n","        print('This environment is Google Colab')\n","        \n","        # mount\n","        from google.colab import drive\n","        if not os.path.isdir('/content/drive'):\n","            drive.mount('/content/drive') \n","        \n","        # import library\n","        ! pip install --quiet tensorflow-addons\n","\n","        # use kaggle api (need kaggle token)\n","        f = open(cfg.api_path, 'r')\n","        json_data = json.load(f) \n","        os.environ['KAGGLE_USERNAME'] = json_data['username']\n","        os.environ['KAGGLE_KEY'] = json_data['key']\n","\n","        # set dirs\n","        cfg.DRIVE = cfg.drive_path\n","        cfg.EXP = (cfg.name if cfg.name is not None \n","            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n","        )\n","        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n","        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n","        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n","        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n","\n","        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n","        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","        \n","        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n","            # load dataset\n","            ! pip install --upgrade --force-reinstall --no-deps kaggle\n","            ! kaggle competitions download -c $cfg.competition -p $cfg.INPUT\n","            filepath = os.path.join(cfg.INPUT,cfg.competition+'.zip')\n","            ! unzip -d $cfg.INPUT $filepath\n","            \n","        \n","        for path in cfg.dataset_path:\n","            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n","            if not os.path.exists(datasetpath):\n","                os.makedirs(datasetpath, exist_ok=True)\n","                ! kaggle datasets download $path -p $datasetpath\n","                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n","                ! unzip -d $datasetpath $filepath\n","\n","        logger = getLogger(\"main\")\n","        logger.setLevel(DEBUG)\n","        formatter = Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","        h = FileHandler(os.path.join(cfg.OUTPUT_EXP ,\"train.log\"))\n","        h.setLevel(INFO)\n","        h.setFormatter(formatter)\n","        logger.addHandler(h)\n","    \n","    else:\n","        print('This environment is Kaggle Kernel')\n","\n","        # set dirs\n","        cfg.INPUT = f'../input/{cfg.competition}'\n","        cfg.EXP = cfg.name\n","        cfg.OUTPUT_EXP = cfg.name\n","        cfg.SUBMISSION = './'\n","        cfg.DATASET = '../input/'\n","        \n","        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n","        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n","        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n","\n","        # make dirs\n","        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n","            os.makedirs(d, exist_ok=True)\n","\n","    seed_everything(cfg.seed)\n","    return cfg\n","\n","\n","def dataset_create_new(dataset_name, upload_dir):\n","    dataset_metadata = {}\n","    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n","    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n","    dataset_metadata['title'] = dataset_name\n","    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n","        json.dump(dataset_metadata, f, indent=4)\n","    api = KaggleApi()\n","    api.authenticate()\n","    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pkn7iysmvcxW"},"outputs":[],"source":["def fit_lightgbm(cfg, X, y, params, folds, add_suffix=''):\n","    oof_pred = np.zeros(len(y), dtype=np.float64)\n","\n","    for fold in cfg.trn_fold:\n","        idx_train = ((folds==fold).groupby(level=0).sum()==0)\n","        idx_valid = ((folds==fold).groupby(level=0).sum()>=1)\n","        x_train, y_train = X[idx_train], y[idx_train]\n","        x_valid, y_valid = X[idx_valid], y[idx_valid]\n","        \n","        lgbm_train = lgbm.Dataset(x_train, y_train)\n","        lgbm_valid = lgbm.Dataset(x_valid, y_valid, reference=lgbm_train)\n","        \n","        model = lgbm.train(\n","            params=params,\n","            train_set=lgbm_train,\n","            valid_sets=[lgbm_train, lgbm_valid],\n","            valid_names=[\"train\", \"valid\"],\n","            num_boost_round=cfg.max_epochs,\n","            verbose_eval=100,\n","            early_stopping_rounds=100,\n","        )\n","        \n","        # save model\n","        tmp_path = os.path.join(Config.EXP_MODEL, f'lgbm_fold{fold}{add_suffix}.pkl')\n","        pickle.dump(model, open(tmp_path, 'wb'))\n","        # save oof-pred\n","        pred_i = model.predict(x_valid, num_iteration=model.best_iteration)\n","        oof_pred = pred_i\n","        tmp_path = os.path.join(Config.EXP_PREDS, f'lgbm_fold{fold}{add_suffix}.npy')\n","        np.save(tmp_path, pred_i)\n","        \n","        score = round(PearsonR(y_valid, pred_i), 5)\n","        print(f'Performance of the prediction: {score}')\n","\n","    # save oof-pred\n","    tmp_path = os.path.join(Config.EXP_PREDS, f'lgbm_foldall{add_suffix}.npy')\n","    np.save(tmp_path, oof_pred)\n","\n","    score = round(PearsonR(y, oof_pred), 5)\n","    print(f'All Performance of the prediction: {score}')\n","    return oof_pred\n","\n","\n","def pred_lightgbm(cfg, X, add_suffix=''):\n","    models = glob(os.path.join(cfg.EXP_MODEL, f'lgbm*{add_suffix}.pkl'))\n","    models = [pickle.load(open(model, 'rb')) for model in models]\n","    preds = np.array([model.predict(X) for model in models])\n","    preds = np.mean(preds, axis=0)\n","    return preds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4858,"status":"ok","timestamp":1644236476944,"user":{"displayName":"巨峰","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ312ml7sKAt5HJP_fBP-ooQm_1_LlrntDA9sW0g=s64","userId":"02610628405275685183"},"user_tz":-540},"id":"vASSOwJQvcxX","outputId":"714e8923-a069-445c-9e1d-0f2eb07291ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["This environment is Google Colab\n"]}],"source":["# =========================\n","# SetUp\n","# =========================\n","Config = setup(Config)\n","logger.info(\"Parameters\")\n","logger.info(\"seed: \" + f\"{Config.seed}\")\n","logger.info(\"n_fold: \" + f\"{Config.n_fold}\")\n","logger.info(\"n_test: \" + f\"{Config.n_test}\")\n","logger.info(\"purge: \" + f\"{Config.purge}\")\n","logger.info(\"embargo: \" + f\"{Config.embargo}\")\n","\n","# 2nd import\n","import tensorflow_addons as tfa"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57791,"status":"ok","timestamp":1644236534727,"user":{"displayName":"巨峰","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ312ml7sKAt5HJP_fBP-ooQm_1_LlrntDA9sW0g=s64","userId":"02610628405275685183"},"user_tz":-540},"id":"ftCfHhdWvcxX","outputId":"97d56b56-eea7-438f-cbe7-f67e2240dda4"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# =========================\n","# Pre-Processing\n","# =========================\n","train = pd.read_parquet(os.path.join(Config.DATASET, 'ubiquant-parquet/train_low_mem.parquet'))\n","train_time = train['time_id']\n","train_investment = train['investment_id']\n","\n","feature_cols = [f'f_{i}' for i in range(300)]\n","train_X = train[['investment_id'] + feature_cols].values.astype(np.float32)\n","train_y = train['target'].values.astype(np.float32)\n","\n","folds = mycv.get_CPGKfold(train, 'target', 'time_id', Config.n_fold, Config.n_test, Config.purge, Config.embargo)\n","\n","del train\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"executionInfo":{"elapsed":53984,"status":"error","timestamp":1644236588694,"user":{"displayName":"巨峰","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjJ312ml7sKAt5HJP_fBP-ooQm_1_LlrntDA9sW0g=s64","userId":"02610628405275685183"},"user_tz":-540},"id":"DfOhSDdrvcxY","outputId":"330ad5db-4fe7-4c70-bf8e-0e2fe71a8813"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n","  import sys\n"]},{"ename":"ValueError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-d8c098612a7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m'num_leaves'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m }\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0moof_base_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_lightgbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgbm_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-0f902db8d7dd>\u001b[0m in \u001b[0;36mfit_lightgbm\u001b[0;34m(cfg, X, y, params, folds, add_suffix)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0midx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0midx_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3447\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3449\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3451\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3500\u001b[0m         \u001b[0;31m# check_bool_indexer will throw exception if Series key cannot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3501\u001b[0m         \u001b[0;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3502\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3503\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m   4578\u001b[0m     )\n\u001b[1;32m   4579\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4580\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4582\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecate_nonkeyword_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4817\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4818\u001b[0m         return self._reindex_axes(\n\u001b[0;32m-> 4819\u001b[0;31m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4820\u001b[0m         ).__finalize__(self, method=\"reindex\")\n\u001b[1;32m   4821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4841\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4842\u001b[0m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4843\u001b[0;31m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4844\u001b[0m             )\n\u001b[1;32m   4845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4887\u001b[0m                 \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4888\u001b[0m                 \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_dups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4889\u001b[0;31m                 \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4890\u001b[0m             )\n\u001b[1;32m   4891\u001b[0m             \u001b[0;31m# If we've made a copy once, no need to make another one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;31m# some axes don't allow reindexing with dups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_can_reindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_validate_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   3783\u001b[0m         \u001b[0;31m# trying to reindex on an axis with duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3785\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot reindex from a duplicate axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3787\u001b[0m     def reindex(\n","\u001b[0;31mValueError\u001b[0m: cannot reindex from a duplicate axis"]}],"source":["# =========================\n","# Training & Upload\n","# =========================\n","lgbm_params = {\n","    'objective': 'rmse',\n","    'metric': 'rmse',\n","    'boosting_type': 'gbdt', \n","    'learning_rate': 0.1, \n","    'num_leaves': 31, \n","}\n","oof_base_pred = fit_lightgbm(Config, train_X, train_y, lgbm_params, folds, '_base')\n","\n","\n","# upload output folder to kaggle dataset\n","if Config.upload_from_colab:\n","    from kaggle.api.kaggle_api_extended import KaggleApi\n","    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wbym_w6gvcxZ"},"outputs":[],"source":[]}],"metadata":{"colab":{"machine_shape":"hm","name":"ubiquant-training-google-colaboratory-training.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}
