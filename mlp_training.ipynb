{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDJWpyf2wRin",
        "outputId": "6dcc0f63-abda-4e4d-c06f-b095df1b8d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Kaggle/UbiquantMarketPredictionDrive/zume/ubiquant_src\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/MyDrive/Kaggle/UbiquantMarketPredictionDrive/zume/ubiquant_src\"\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO6Pl5tAvcxN",
        "outputId": "363e41d9-ec67-48b3-be81-1eadf66274c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb 19 10:59:33 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2MrvRuLrvcxP"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    author = \"zume\" # Your name\n",
        "    competition = \"ubiquant-market-prediction\"\n",
        "    name = \"MLP011\" # The name of the Dataset\n",
        "    upload_from_colab = True # If True, the model uploads to the Kaggle Dataset\n",
        "    \n",
        "    colab_dir = \"/content/drive/MyDrive/Kaggle/UbiquantMarketPredictionDrive\" # Your own directory\n",
        "    drive_path = colab_dir + f\"/{author}\"\n",
        "    api_path = \"/content/drive/MyDrive/Kaggle/kaggle.json\" # Your own api-path\n",
        "    \n",
        "    dataset_path = ['robikscube/ubiquant-parquet'] # The dataset you want to download\n",
        "\n",
        "    n_fold = 5\n",
        "    n_test = 1\n",
        "    purge = 10\n",
        "    embargo = 0.01\n",
        "\n",
        "    n_units = [300, 128, 64, 16]\n",
        "    \n",
        "    from scipy.special import comb\n",
        "    trn_fold = [i for i in range(comb(n_fold, n_test, exact=True))]\n",
        "    seed = 42\n",
        "    max_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M4BWPj1qvcxR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import sys\n",
        "import json\n",
        "import pickle\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "import requests\n",
        "import itertools\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from logging import StreamHandler, FileHandler, Formatter, getLogger, DEBUG, INFO\n",
        "\n",
        "from sklearn.preprocessing import (\n",
        "    StandardScaler,\n",
        "    MinMaxScaler,\n",
        "    RobustScaler,\n",
        ")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tensorflow as tf\n",
        "\n",
        "sys.path.append(\"/content/drive/MyDrive/Kaggle/UbiquantMarketPredictionDrive/zume/ubiquant_src\")\n",
        "import mycv\n",
        "\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def MAE(y_true, y_pred):\n",
        "    return mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "def MSE(y_true, y_pred):\n",
        "    return mean_squared_error(y_true, y_pred)\n",
        "\n",
        "def RMSE(y_true, y_pred):\n",
        "    return mean_squared_error(y_true, y_pred, squared=False)\n",
        "\n",
        "def PearsonR(y_true, y_pred):\n",
        "    return scipy.stats.pearsonr(y_true, y_pred)[0]\n",
        "\n",
        "def PearsonR_metric(y_true, y_pred):\n",
        "    return \"pearsonr\", scipy.stats.pearsonr(y_true, y_pred)[0], True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sN3gZyhyGzb-"
      },
      "outputs": [],
      "source": [
        "class UbiquantDataset(Dataset):\n",
        "    def __init__(self, df, mode=\"train\"):\n",
        "        self.mode = mode\n",
        "        self.features = df[[f\"f_{i}\" for i in range(300)]].values\n",
        "        if self.mode != \"test\":\n",
        "            self.targets = df[\"target\"].values\n",
        "        self.len = df.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if self.mode != \"test\":\n",
        "            return self.features[index], self.targets[index]\n",
        "        else:\n",
        "            return self.features[index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FIlIQHYxGzb_",
        "outputId": "f306d4c9-ed62-4b38-a4dc-954ddcdf2273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "class Swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, n_units):\n",
        "        super().__init__()\n",
        "        self.n_units = n_units\n",
        "        self.n_blocks = len(n_units) - 1\n",
        "\n",
        "        seq_list = np.array([\n",
        "                   [\n",
        "                    (f\"linear{i}\", nn.Linear(self.n_units[i], self.n_units[i+1])),\n",
        "                    (f\"actv{i}\", Swish())\n",
        "                    ] for i in range(self.n_blocks)\n",
        "        ])\n",
        "        self.seq = nn.Sequential(OrderedDict(np.concatenate(seq_list)))\n",
        "\n",
        "        self.lastf = nn.Linear(self.n_units[-1], 1)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.seq(x)\n",
        "        x = self.lastf(x)\n",
        "        return x\n",
        "    \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9qw82OTLGzcA"
      },
      "outputs": [],
      "source": [
        "def train_fn(cfg, train, fold, folds):\n",
        "    model = MLP(cfg.n_units).to(device)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
        "    epochs = cfg.max_epochs\n",
        "\n",
        "    idx_train = ((folds==fold).groupby(level=0).sum()==0)\n",
        "    idx_valid = ((folds==fold).groupby(level=0).sum()>=1)\n",
        "\n",
        "    train_set = UbiquantDataset(train[idx_train], mode=\"train\")\n",
        "    valid_set = UbiquantDataset(train[idx_valid], mode=\"valid\")\n",
        "    dataloaders = {\n",
        "        \"train\": DataLoader(train_set, batch_size=512, num_workers=4, pin_memory=True),\n",
        "        \"valid\": DataLoader(valid_set, batch_size=512, num_workers=4, pin_memory=True)\n",
        "        }\n",
        "        \n",
        "    num_train = len(dataloaders[\"train\"])\n",
        "    num_valid = len(dataloaders[\"valid\"])\n",
        "\n",
        "    losses = []\n",
        "    best_loss = np.inf\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for i, (features, targets) in enumerate(dataloaders[\"train\"]):\n",
        "            features = features.float().to(device)\n",
        "            targets = targets.unsqueeze(1).to(device)\n",
        "\n",
        "            y = model(features)\n",
        "            loss = loss_fn(y, targets)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        train_epoch_loss = train_loss / num_train\n",
        "\n",
        "        model.eval()\n",
        "        valid_preds = []\n",
        "        valid_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for i, (features, targets) in enumerate(dataloaders[\"valid\"]):\n",
        "                features = features.float().to(device)\n",
        "                targets = targets.unsqueeze(1).to(device)\n",
        "\n",
        "                y = model(features)\n",
        "                loss = loss_fn(y, targets)\n",
        "                \n",
        "                valid_loss += loss.item()\n",
        "                valid_preds.extend(y.detach().cpu().numpy().flatten())\n",
        "            valid_epoch_loss = valid_loss / num_valid\n",
        "        \n",
        "        scheduler.step()\n",
        "        oof = train[idx_valid][['target']].copy()\n",
        "        oof['pred'] = valid_preds\n",
        "        score = oof['pred'].corr(oof['target'])\n",
        "\n",
        "        losses.append((train_epoch_loss, valid_epoch_loss))\n",
        "        logger.info(f\"EPOCH:{epoch}, LR:{optimizer.param_groups[0]['lr']}\")\n",
        "        logger.info(f\"Train loss: {train_epoch_loss:.6f}\")\n",
        "        logger.info(f\"Valid loss: {valid_epoch_loss:.6f}\")\n",
        "        logger.info(f\"PearsonR score: {score:.6f}\")\n",
        "\n",
        "        if best_loss > valid_epoch_loss:\n",
        "            torch.save(model.state_dict(), os.path.join(cfg.EXP_MODEL, f\"model_{fold}.pth\"))\n",
        "            best_loss = valid_epoch_loss\n",
        "    \n",
        "    return losses, oof"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dKeJYuRvvcxU"
      },
      "outputs": [],
      "source": [
        "def setup(cfg):\n",
        "    cfg.COLAB = 'google.colab' in sys.modules\n",
        "    if cfg.COLAB:\n",
        "        global logger\n",
        "        print('This environment is Google Colab')\n",
        "        \n",
        "        # mount\n",
        "        from google.colab import drive\n",
        "        if not os.path.isdir('/content/drive'):\n",
        "            drive.mount('/content/drive') \n",
        "        \n",
        "        # import library\n",
        "        ! pip install --quiet tensorflow-addons\n",
        "\n",
        "        # use kaggle api (need kaggle token)\n",
        "        f = open(cfg.api_path, 'r')\n",
        "        json_data = json.load(f) \n",
        "        os.environ['KAGGLE_USERNAME'] = json_data['username']\n",
        "        os.environ['KAGGLE_KEY'] = json_data['key']\n",
        "\n",
        "        # set dirs\n",
        "        cfg.DRIVE = cfg.drive_path\n",
        "        cfg.EXP = (cfg.name if cfg.name is not None \n",
        "            else requests.get('http://172.28.0.2:9000/api/sessions').json()[0]['name'][:-6]\n",
        "        )\n",
        "        cfg.INPUT = os.path.join(cfg.DRIVE, 'Input')\n",
        "        cfg.OUTPUT = os.path.join(cfg.DRIVE, 'Output')\n",
        "        cfg.SUBMISSION = os.path.join(cfg.DRIVE, 'Submission')\n",
        "        cfg.DATASET = os.path.join(cfg.DRIVE, 'Dataset')\n",
        "\n",
        "        cfg.OUTPUT_EXP = os.path.join(cfg.OUTPUT, cfg.EXP) \n",
        "        cfg.EXP_MODEL = os.path.join(cfg.OUTPUT_EXP, 'model')\n",
        "        cfg.EXP_FIG = os.path.join(cfg.OUTPUT_EXP, 'fig')\n",
        "        cfg.EXP_PREDS = os.path.join(cfg.OUTPUT_EXP, 'preds')\n",
        "\n",
        "        # make dirs\n",
        "        for d in [cfg.INPUT, cfg.SUBMISSION, cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n",
        "            os.makedirs(d, exist_ok=True)\n",
        "        \n",
        "        if not os.path.isfile(os.path.join(cfg.INPUT, 'train.csv')):\n",
        "            # load dataset\n",
        "            ! pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "            ! kaggle competitions download -c $cfg.competition -p $cfg.INPUT\n",
        "            filepath = os.path.join(cfg.INPUT,cfg.competition+'.zip')\n",
        "            ! unzip -d $cfg.INPUT $filepath\n",
        "            \n",
        "        \n",
        "        for path in cfg.dataset_path:\n",
        "            datasetpath = os.path.join(cfg.DATASET,  path.split('/')[1])\n",
        "            if not os.path.exists(datasetpath):\n",
        "                os.makedirs(datasetpath, exist_ok=True)\n",
        "                ! kaggle datasets download $path -p $datasetpath\n",
        "                filepath = os.path.join(datasetpath, path.split(\"/\")[1]+'.zip')\n",
        "                ! unzip -d $datasetpath $filepath\n",
        "\n",
        "        logger = getLogger(\"main\")\n",
        "        logger.setLevel(DEBUG)\n",
        "        formatter = Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "        h = FileHandler(os.path.join(cfg.OUTPUT_EXP ,\"train.log\"))\n",
        "        h.setLevel(INFO)\n",
        "        h.setFormatter(formatter)\n",
        "        sh = StreamHandler()\n",
        "        sh.setLevel(DEBUG)\n",
        "        sh.setFormatter(formatter)\n",
        "        logger.addHandler(h)\n",
        "        logger.addHandler(sh)\n",
        "    \n",
        "    else:\n",
        "        print('This environment is Kaggle Kernel')\n",
        "\n",
        "        # set dirs\n",
        "        cfg.INPUT = f'../input/{cfg.competition}'\n",
        "        cfg.EXP = cfg.name\n",
        "        cfg.OUTPUT_EXP = cfg.name\n",
        "        cfg.SUBMISSION = './'\n",
        "        cfg.DATASET = '../input/'\n",
        "        \n",
        "        cfg.EXP_MODEL = os.path.join(cfg.EXP, 'model')\n",
        "        cfg.EXP_FIG = os.path.join(cfg.EXP, 'fig')\n",
        "        cfg.EXP_PREDS = os.path.join(cfg.EXP, 'preds')\n",
        "\n",
        "        # make dirs\n",
        "        for d in [cfg.EXP_MODEL, cfg.EXP_FIG, cfg.EXP_PREDS]:\n",
        "            os.makedirs(d, exist_ok=True)\n",
        "\n",
        "    seed_everything(cfg.seed)\n",
        "    return cfg\n",
        "\n",
        "\n",
        "def dataset_create_new(dataset_name, upload_dir):\n",
        "    dataset_metadata = {}\n",
        "    dataset_metadata['id'] = f'{os.environ[\"KAGGLE_USERNAME\"]}/{dataset_name}'\n",
        "    dataset_metadata['licenses'] = [{'name': 'CC0-1.0'}]\n",
        "    dataset_metadata['title'] = dataset_name\n",
        "    with open(os.path.join(upload_dir, 'dataset-metadata.json'), 'w') as f:\n",
        "        json.dump(dataset_metadata, f, indent=4)\n",
        "    api = KaggleApi()\n",
        "    api.authenticate()\n",
        "    api.dataset_create_new(folder=upload_dir, convert_to_csv=False, dir_mode='tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "InS69M3LGzcD"
      },
      "outputs": [],
      "source": [
        "def fit_mlp(cfg, train, folds):\n",
        "    oof_list = []\n",
        "\n",
        "    for fold in cfg.trn_fold:\n",
        "        losses, oof = train_fn(cfg, train, fold, folds)\n",
        "        oof_list.append(oof)\n",
        "    oof = pd.concat(oof_list)\n",
        "    logger.info(f\"OOF PearsonR score: {oof['pred'].corr(oof['target'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vASSOwJQvcxX",
        "outputId": "f68cee3b-a831-475e-8ad9-21daac8f996a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This environment is Google Colab\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-02-19 10:59:40,648 - main - INFO - Parameters\n",
            "2022-02-19 10:59:40,650 - main - INFO - seed: 42\n",
            "2022-02-19 10:59:40,655 - main - INFO - n_fold: 5\n",
            "2022-02-19 10:59:40,658 - main - INFO - n_test: 1\n",
            "2022-02-19 10:59:40,661 - main - INFO - purge: 10\n",
            "2022-02-19 10:59:40,664 - main - INFO - embargo: 0.01\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# SetUp\n",
        "# =========================\n",
        "Config = setup(Config)\n",
        "logger.info(\"Parameters\")\n",
        "logger.info(\"seed: \" + f\"{Config.seed}\")\n",
        "logger.info(\"n_fold: \" + f\"{Config.n_fold}\")\n",
        "logger.info(\"n_test: \" + f\"{Config.n_test}\")\n",
        "logger.info(\"purge: \" + f\"{Config.purge}\")\n",
        "logger.info(\"embargo: \" + f\"{Config.embargo}\")\n",
        "\n",
        "# 2nd import\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftCfHhdWvcxX",
        "outputId": "33633c93-e237-4001-cc0c-2bcd76c64a6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# =========================\n",
        "# Pre-Processing\n",
        "# =========================\n",
        "train = pd.read_parquet(os.path.join(Config.DATASET, 'ubiquant-parquet/train_neglog.parquet'))\n",
        "train = train.sort_values(\"time_id\").reset_index(drop=True)\n",
        "# folds = mycv.get_CPGKfold(train, 'target', 'time_id', Config.n_fold, Config.n_test, Config.purge, Config.embargo)\n",
        "folds = mycv.get_timeseriesfold(train, Config.n_fold)\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfOhSDdrvcxY",
        "outputId": "6f46b249-296a-4cfe-efd3-544f6b2e52b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-02-19 11:00:36,601 - main - INFO - EPOCH:0, LR:0.0009000000000000001\n",
            "2022-02-19 11:00:36,602 - main - INFO - Train loss: 0.840495\n",
            "2022-02-19 11:00:36,604 - main - INFO - Valid loss: 0.812803\n",
            "2022-02-19 11:00:36,606 - main - INFO - PearsonR score: 0.100064\n",
            "2022-02-19 11:00:59,514 - main - INFO - EPOCH:1, LR:0.0008100000000000001\n",
            "2022-02-19 11:00:59,516 - main - INFO - Train loss: 0.836441\n",
            "2022-02-19 11:00:59,517 - main - INFO - Valid loss: 0.810280\n",
            "2022-02-19 11:00:59,520 - main - INFO - PearsonR score: 0.111214\n",
            "2022-02-19 11:01:22,983 - main - INFO - EPOCH:2, LR:0.000729\n",
            "2022-02-19 11:01:22,985 - main - INFO - Train loss: 0.834174\n",
            "2022-02-19 11:01:22,986 - main - INFO - Valid loss: 0.810156\n",
            "2022-02-19 11:01:22,988 - main - INFO - PearsonR score: 0.113347\n",
            "2022-02-19 11:01:45,968 - main - INFO - EPOCH:3, LR:0.0006561000000000001\n",
            "2022-02-19 11:01:45,970 - main - INFO - Train loss: 0.832386\n",
            "2022-02-19 11:01:45,972 - main - INFO - Valid loss: 0.809515\n",
            "2022-02-19 11:01:45,973 - main - INFO - PearsonR score: 0.113568\n",
            "2022-02-19 11:02:08,902 - main - INFO - EPOCH:4, LR:0.00059049\n",
            "2022-02-19 11:02:08,904 - main - INFO - Train loss: 0.830866\n",
            "2022-02-19 11:02:08,905 - main - INFO - Valid loss: 0.808851\n",
            "2022-02-19 11:02:08,907 - main - INFO - PearsonR score: 0.114698\n",
            "2022-02-19 11:02:31,964 - main - INFO - EPOCH:5, LR:0.000531441\n",
            "2022-02-19 11:02:31,967 - main - INFO - Train loss: 0.829100\n",
            "2022-02-19 11:02:31,968 - main - INFO - Valid loss: 0.808595\n",
            "2022-02-19 11:02:31,971 - main - INFO - PearsonR score: 0.113154\n",
            "2022-02-19 11:02:54,825 - main - INFO - EPOCH:6, LR:0.0004782969\n",
            "2022-02-19 11:02:54,827 - main - INFO - Train loss: 0.827182\n",
            "2022-02-19 11:02:54,828 - main - INFO - Valid loss: 0.808901\n",
            "2022-02-19 11:02:54,831 - main - INFO - PearsonR score: 0.111567\n",
            "2022-02-19 11:03:17,809 - main - INFO - EPOCH:7, LR:0.00043046721\n",
            "2022-02-19 11:03:17,811 - main - INFO - Train loss: 0.825295\n",
            "2022-02-19 11:03:17,812 - main - INFO - Valid loss: 0.809596\n",
            "2022-02-19 11:03:17,814 - main - INFO - PearsonR score: 0.110887\n",
            "2022-02-19 11:03:40,827 - main - INFO - EPOCH:8, LR:0.000387420489\n",
            "2022-02-19 11:03:40,829 - main - INFO - Train loss: 0.823450\n",
            "2022-02-19 11:03:40,831 - main - INFO - Valid loss: 0.810042\n",
            "2022-02-19 11:03:40,833 - main - INFO - PearsonR score: 0.111925\n",
            "2022-02-19 11:04:03,912 - main - INFO - EPOCH:9, LR:0.0003486784401\n",
            "2022-02-19 11:04:03,914 - main - INFO - Train loss: 0.821753\n",
            "2022-02-19 11:04:03,915 - main - INFO - Valid loss: 0.811606\n",
            "2022-02-19 11:04:03,917 - main - INFO - PearsonR score: 0.110646\n",
            "2022-02-19 11:04:30,309 - main - INFO - EPOCH:0, LR:0.0009000000000000001\n",
            "2022-02-19 11:04:30,311 - main - INFO - Train loss: 0.830922\n",
            "2022-02-19 11:04:30,313 - main - INFO - Valid loss: 0.852377\n",
            "2022-02-19 11:04:30,314 - main - INFO - PearsonR score: 0.093579\n",
            "2022-02-19 11:04:53,158 - main - INFO - EPOCH:1, LR:0.0008100000000000001\n",
            "2022-02-19 11:04:53,159 - main - INFO - Train loss: 0.827088\n",
            "2022-02-19 11:04:53,161 - main - INFO - Valid loss: 0.849695\n",
            "2022-02-19 11:04:53,162 - main - INFO - PearsonR score: 0.101733\n",
            "2022-02-19 11:05:16,227 - main - INFO - EPOCH:2, LR:0.000729\n",
            "2022-02-19 11:05:16,229 - main - INFO - Train loss: 0.825104\n",
            "2022-02-19 11:05:16,230 - main - INFO - Valid loss: 0.849578\n",
            "2022-02-19 11:05:16,233 - main - INFO - PearsonR score: 0.102884\n",
            "2022-02-19 11:05:39,455 - main - INFO - EPOCH:3, LR:0.0006561000000000001\n",
            "2022-02-19 11:05:39,457 - main - INFO - Train loss: 0.823441\n",
            "2022-02-19 11:05:39,459 - main - INFO - Valid loss: 0.849493\n",
            "2022-02-19 11:05:39,461 - main - INFO - PearsonR score: 0.103684\n",
            "2022-02-19 11:06:02,590 - main - INFO - EPOCH:4, LR:0.00059049\n",
            "2022-02-19 11:06:02,592 - main - INFO - Train loss: 0.821720\n",
            "2022-02-19 11:06:02,593 - main - INFO - Valid loss: 0.848668\n",
            "2022-02-19 11:06:02,595 - main - INFO - PearsonR score: 0.106788\n",
            "2022-02-19 11:06:25,486 - main - INFO - EPOCH:5, LR:0.000531441\n",
            "2022-02-19 11:06:25,488 - main - INFO - Train loss: 0.820015\n",
            "2022-02-19 11:06:25,489 - main - INFO - Valid loss: 0.848559\n",
            "2022-02-19 11:06:25,490 - main - INFO - PearsonR score: 0.107858\n",
            "2022-02-19 11:06:48,495 - main - INFO - EPOCH:6, LR:0.0004782969\n",
            "2022-02-19 11:06:48,497 - main - INFO - Train loss: 0.818021\n",
            "2022-02-19 11:06:48,502 - main - INFO - Valid loss: 0.848876\n",
            "2022-02-19 11:06:48,504 - main - INFO - PearsonR score: 0.108073\n",
            "2022-02-19 11:07:11,367 - main - INFO - EPOCH:7, LR:0.00043046721\n",
            "2022-02-19 11:07:11,369 - main - INFO - Train loss: 0.816080\n",
            "2022-02-19 11:07:11,371 - main - INFO - Valid loss: 0.848899\n",
            "2022-02-19 11:07:11,373 - main - INFO - PearsonR score: 0.109219\n",
            "2022-02-19 11:07:34,279 - main - INFO - EPOCH:8, LR:0.000387420489\n",
            "2022-02-19 11:07:34,281 - main - INFO - Train loss: 0.814122\n",
            "2022-02-19 11:07:34,283 - main - INFO - Valid loss: 0.849070\n",
            "2022-02-19 11:07:34,285 - main - INFO - PearsonR score: 0.110249\n",
            "2022-02-19 11:07:57,250 - main - INFO - EPOCH:9, LR:0.0003486784401\n",
            "2022-02-19 11:07:57,251 - main - INFO - Train loss: 0.812183\n",
            "2022-02-19 11:07:57,253 - main - INFO - Valid loss: 0.849761\n",
            "2022-02-19 11:07:57,254 - main - INFO - PearsonR score: 0.110122\n",
            "2022-02-19 11:08:23,523 - main - INFO - EPOCH:0, LR:0.0009000000000000001\n",
            "2022-02-19 11:08:23,525 - main - INFO - Train loss: 0.829709\n",
            "2022-02-19 11:08:23,526 - main - INFO - Valid loss: 0.854087\n",
            "2022-02-19 11:08:23,528 - main - INFO - PearsonR score: 0.087197\n",
            "2022-02-19 11:08:46,517 - main - INFO - EPOCH:1, LR:0.0008100000000000001\n",
            "2022-02-19 11:08:46,519 - main - INFO - Train loss: 0.825860\n",
            "2022-02-19 11:08:46,521 - main - INFO - Valid loss: 0.853999\n",
            "2022-02-19 11:08:46,522 - main - INFO - PearsonR score: 0.091708\n",
            "2022-02-19 11:09:09,369 - main - INFO - EPOCH:2, LR:0.000729\n",
            "2022-02-19 11:09:09,371 - main - INFO - Train loss: 0.823484\n",
            "2022-02-19 11:09:09,373 - main - INFO - Valid loss: 0.852841\n",
            "2022-02-19 11:09:09,374 - main - INFO - PearsonR score: 0.096369\n",
            "2022-02-19 11:09:32,258 - main - INFO - EPOCH:3, LR:0.0006561000000000001\n",
            "2022-02-19 11:09:32,260 - main - INFO - Train loss: 0.821583\n",
            "2022-02-19 11:09:32,262 - main - INFO - Valid loss: 0.852593\n",
            "2022-02-19 11:09:32,264 - main - INFO - PearsonR score: 0.096900\n",
            "2022-02-19 11:09:55,243 - main - INFO - EPOCH:4, LR:0.00059049\n",
            "2022-02-19 11:09:55,245 - main - INFO - Train loss: 0.819791\n",
            "2022-02-19 11:09:55,246 - main - INFO - Valid loss: 0.851928\n",
            "2022-02-19 11:09:55,249 - main - INFO - PearsonR score: 0.099495\n",
            "2022-02-19 11:10:18,174 - main - INFO - EPOCH:5, LR:0.000531441\n",
            "2022-02-19 11:10:18,175 - main - INFO - Train loss: 0.817983\n",
            "2022-02-19 11:10:18,177 - main - INFO - Valid loss: 0.852269\n",
            "2022-02-19 11:10:18,179 - main - INFO - PearsonR score: 0.098858\n",
            "2022-02-19 11:10:41,356 - main - INFO - EPOCH:6, LR:0.0004782969\n",
            "2022-02-19 11:10:41,357 - main - INFO - Train loss: 0.816062\n",
            "2022-02-19 11:10:41,359 - main - INFO - Valid loss: 0.853016\n",
            "2022-02-19 11:10:41,361 - main - INFO - PearsonR score: 0.097835\n",
            "2022-02-19 11:11:05,181 - main - INFO - EPOCH:7, LR:0.00043046721\n",
            "2022-02-19 11:11:05,182 - main - INFO - Train loss: 0.814053\n",
            "2022-02-19 11:11:05,184 - main - INFO - Valid loss: 0.853523\n",
            "2022-02-19 11:11:05,188 - main - INFO - PearsonR score: 0.097941\n",
            "2022-02-19 11:11:28,061 - main - INFO - EPOCH:8, LR:0.000387420489\n",
            "2022-02-19 11:11:28,063 - main - INFO - Train loss: 0.812222\n",
            "2022-02-19 11:11:28,065 - main - INFO - Valid loss: 0.854016\n",
            "2022-02-19 11:11:28,067 - main - INFO - PearsonR score: 0.097623\n",
            "2022-02-19 11:11:51,001 - main - INFO - EPOCH:9, LR:0.0003486784401\n",
            "2022-02-19 11:11:51,003 - main - INFO - Train loss: 0.810493\n",
            "2022-02-19 11:11:51,004 - main - INFO - Valid loss: 0.854623\n",
            "2022-02-19 11:11:51,007 - main - INFO - PearsonR score: 0.097476\n",
            "2022-02-19 11:12:17,084 - main - INFO - EPOCH:0, LR:0.0009000000000000001\n",
            "2022-02-19 11:12:17,086 - main - INFO - Train loss: 0.828899\n",
            "2022-02-19 11:12:17,087 - main - INFO - Valid loss: 0.854550\n",
            "2022-02-19 11:12:17,089 - main - INFO - PearsonR score: 0.110988\n",
            "2022-02-19 11:12:40,114 - main - INFO - EPOCH:1, LR:0.0008100000000000001\n",
            "2022-02-19 11:12:40,117 - main - INFO - Train loss: 0.825293\n",
            "2022-02-19 11:12:40,118 - main - INFO - Valid loss: 0.852319\n",
            "2022-02-19 11:12:40,121 - main - INFO - PearsonR score: 0.120994\n",
            "2022-02-19 11:13:03,110 - main - INFO - EPOCH:2, LR:0.000729\n",
            "2022-02-19 11:13:03,112 - main - INFO - Train loss: 0.822872\n",
            "2022-02-19 11:13:03,114 - main - INFO - Valid loss: 0.852678\n",
            "2022-02-19 11:13:03,116 - main - INFO - PearsonR score: 0.121168\n",
            "2022-02-19 11:13:26,183 - main - INFO - EPOCH:3, LR:0.0006561000000000001\n",
            "2022-02-19 11:13:26,185 - main - INFO - Train loss: 0.821394\n",
            "2022-02-19 11:13:26,186 - main - INFO - Valid loss: 0.851569\n",
            "2022-02-19 11:13:26,189 - main - INFO - PearsonR score: 0.125373\n",
            "2022-02-19 11:13:49,173 - main - INFO - EPOCH:4, LR:0.00059049\n",
            "2022-02-19 11:13:49,175 - main - INFO - Train loss: 0.819443\n",
            "2022-02-19 11:13:49,176 - main - INFO - Valid loss: 0.852393\n",
            "2022-02-19 11:13:49,180 - main - INFO - PearsonR score: 0.124467\n",
            "2022-02-19 11:14:12,136 - main - INFO - EPOCH:5, LR:0.000531441\n",
            "2022-02-19 11:14:12,137 - main - INFO - Train loss: 0.817734\n",
            "2022-02-19 11:14:12,140 - main - INFO - Valid loss: 0.852516\n",
            "2022-02-19 11:14:12,142 - main - INFO - PearsonR score: 0.124749\n",
            "2022-02-19 11:14:35,025 - main - INFO - EPOCH:6, LR:0.0004782969\n",
            "2022-02-19 11:14:35,027 - main - INFO - Train loss: 0.815868\n",
            "2022-02-19 11:14:35,029 - main - INFO - Valid loss: 0.852862\n",
            "2022-02-19 11:14:35,031 - main - INFO - PearsonR score: 0.125329\n",
            "2022-02-19 11:14:57,954 - main - INFO - EPOCH:7, LR:0.00043046721\n",
            "2022-02-19 11:14:57,956 - main - INFO - Train loss: 0.813787\n",
            "2022-02-19 11:14:57,958 - main - INFO - Valid loss: 0.853895\n",
            "2022-02-19 11:14:57,960 - main - INFO - PearsonR score: 0.124280\n",
            "2022-02-19 11:15:20,944 - main - INFO - EPOCH:8, LR:0.000387420489\n",
            "2022-02-19 11:15:20,946 - main - INFO - Train loss: 0.811862\n",
            "2022-02-19 11:15:20,949 - main - INFO - Valid loss: 0.855215\n",
            "2022-02-19 11:15:20,950 - main - INFO - PearsonR score: 0.122222\n",
            "2022-02-19 11:15:44,163 - main - INFO - EPOCH:9, LR:0.0003486784401\n",
            "2022-02-19 11:15:44,165 - main - INFO - Train loss: 0.810041\n",
            "2022-02-19 11:15:44,168 - main - INFO - Valid loss: 0.856426\n",
            "2022-02-19 11:15:44,170 - main - INFO - PearsonR score: 0.120378\n",
            "2022-02-19 11:16:10,409 - main - INFO - EPOCH:0, LR:0.0009000000000000001\n",
            "2022-02-19 11:16:10,411 - main - INFO - Train loss: 0.839154\n",
            "2022-02-19 11:16:10,412 - main - INFO - Valid loss: 0.801778\n",
            "2022-02-19 11:16:10,416 - main - INFO - PearsonR score: 0.125854\n",
            "2022-02-19 11:16:33,578 - main - INFO - EPOCH:1, LR:0.0008100000000000001\n",
            "2022-02-19 11:16:33,580 - main - INFO - Train loss: 0.835333\n",
            "2022-02-19 11:16:33,581 - main - INFO - Valid loss: 0.799145\n",
            "2022-02-19 11:16:33,588 - main - INFO - PearsonR score: 0.137069\n",
            "2022-02-19 11:16:56,565 - main - INFO - EPOCH:2, LR:0.000729\n",
            "2022-02-19 11:16:56,567 - main - INFO - Train loss: 0.832956\n",
            "2022-02-19 11:16:56,569 - main - INFO - Valid loss: 0.798556\n",
            "2022-02-19 11:16:56,571 - main - INFO - PearsonR score: 0.139485\n",
            "2022-02-19 11:17:19,620 - main - INFO - EPOCH:3, LR:0.0006561000000000001\n",
            "2022-02-19 11:17:19,622 - main - INFO - Train loss: 0.831380\n",
            "2022-02-19 11:17:19,623 - main - INFO - Valid loss: 0.798112\n",
            "2022-02-19 11:17:19,626 - main - INFO - PearsonR score: 0.141388\n",
            "2022-02-19 11:17:42,535 - main - INFO - EPOCH:4, LR:0.00059049\n",
            "2022-02-19 11:17:42,537 - main - INFO - Train loss: 0.829577\n",
            "2022-02-19 11:17:42,538 - main - INFO - Valid loss: 0.798198\n",
            "2022-02-19 11:17:42,540 - main - INFO - PearsonR score: 0.141769\n",
            "2022-02-19 11:18:05,600 - main - INFO - EPOCH:5, LR:0.000531441\n",
            "2022-02-19 11:18:05,602 - main - INFO - Train loss: 0.827635\n",
            "2022-02-19 11:18:05,603 - main - INFO - Valid loss: 0.798674\n",
            "2022-02-19 11:18:05,606 - main - INFO - PearsonR score: 0.141247\n",
            "2022-02-19 11:18:28,505 - main - INFO - EPOCH:6, LR:0.0004782969\n",
            "2022-02-19 11:18:28,507 - main - INFO - Train loss: 0.825732\n",
            "2022-02-19 11:18:28,508 - main - INFO - Valid loss: 0.799342\n",
            "2022-02-19 11:18:28,511 - main - INFO - PearsonR score: 0.141403\n",
            "2022-02-19 11:18:51,484 - main - INFO - EPOCH:7, LR:0.00043046721\n",
            "2022-02-19 11:18:51,486 - main - INFO - Train loss: 0.823724\n",
            "2022-02-19 11:18:51,488 - main - INFO - Valid loss: 0.800659\n",
            "2022-02-19 11:18:51,490 - main - INFO - PearsonR score: 0.139898\n",
            "2022-02-19 11:19:14,346 - main - INFO - EPOCH:8, LR:0.000387420489\n",
            "2022-02-19 11:19:14,348 - main - INFO - Train loss: 0.821687\n",
            "2022-02-19 11:19:14,349 - main - INFO - Valid loss: 0.802335\n",
            "2022-02-19 11:19:14,353 - main - INFO - PearsonR score: 0.137830\n",
            "2022-02-19 11:19:37,381 - main - INFO - EPOCH:9, LR:0.0003486784401\n",
            "2022-02-19 11:19:37,383 - main - INFO - Train loss: 0.819722\n",
            "2022-02-19 11:19:37,385 - main - INFO - Valid loss: 0.804401\n",
            "2022-02-19 11:19:37,386 - main - INFO - PearsonR score: 0.135939\n",
            "2022-02-19 11:19:37,505 - main - INFO - OOF PearsonR score: 0.11514272885089859\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# Training & Upload\n",
        "# =========================\n",
        "\n",
        "fit_mlp(cfg=Config, train=train, folds=folds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Wbym_w6gvcxZ",
        "outputId": "d3ec2a03-074b-4f35-c526-e04177d5a998",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting upload for file model.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 960k/960k [00:01<00:00, 530kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload successful: model.tar (960KB)\n",
            "Starting upload for file fig.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10.0k/10.0k [00:02<00:00, 4.90kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload successful: fig.tar (10KB)\n",
            "Starting upload for file preds.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10.0k/10.0k [00:01<00:00, 5.36kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload successful: preds.tar (10KB)\n",
            "Starting upload for file train.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12.8k/12.8k [00:01<00:00, 7.02kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload successful: train.log (13KB)\n"
          ]
        }
      ],
      "source": [
        "# upload output folder to kaggle dataset\n",
        "if Config.upload_from_colab:\n",
        "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "    dataset_create_new(dataset_name=Config.EXP, upload_dir=Config.OUTPUT_EXP)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "ubiquant-training-google-colaboratory-training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}